# GPT vLLM Service

## ç®€ä»‹
è¿™æ˜¯ä¸€ä¸ªåŸºäº **FastAPI + vLLM** çš„æ¨ç†æœåŠ¡ï¼Œæ”¯æŒåŠ è½½æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ LLaMA 3ï¼‰ï¼Œå¹¶é€šè¿‡ REST API æä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š

- é€šç”¨å¯¹è¯ï¼ˆChatï¼‰
- å•†å“æ¨å¹¿æ–‡æ¡ˆï¼ˆProductï¼‰
- é—¨åº—æ¨å¹¿æ–‡æ¡ˆï¼ˆStoreï¼‰
- çŸ­è§†é¢‘è„šæœ¬ï¼ˆVideo Scriptï¼‰

æ”¯æŒå¤šè¯­è¨€ï¼ˆä¸­æ–‡ã€è‹±æ–‡ã€è¥¿ç­ç‰™è¯­ï¼‰å’Œå¤šç§é£æ ¼ï¼ˆè¯´æœå‹ã€æ•™è‚²å‹ã€ä¼‘é—²å‹ã€æƒå¨å‹ï¼‰ã€‚

---

## é¡¹ç›®ç»“æ„
```
GPT/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py              # FastAPI å¯åŠ¨å…¥å£
â”‚   â”œâ”€â”€ models.py            # Pydantic æ•°æ®æ¨¡å‹
â”‚   â””â”€â”€ service/
â”‚       â”œâ”€â”€ client.py        # vLLMService å°è£…
â”‚       â”œâ”€â”€ prompts.py       # Prompt æ¨¡æ¿
â”‚       â”œâ”€â”€ router.py        # API è·¯ç”±
â”‚       â””â”€â”€ deps.py          # ä¾èµ–æ³¨å…¥
â”œâ”€â”€ clients/
â”‚   â””â”€â”€ python/
â”‚       â”œâ”€â”€ chatagent.py     # äº¤äº’å¼å¯¹è¯å®¢æˆ·ç«¯
â”‚       â””â”€â”€ gen_once.py      # ä¸€æ¬¡æ€§è°ƒç”¨å®¢æˆ·ç«¯
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ vllm.yaml            # vLLM é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### requirements.txt
```txt
fastapi>=0.110.0
uvicorn[standard]>=0.29.0
pydantic>=2.7.0
pyyaml>=6.0
requests>=2.31.0
vllm>=0.4.2
```

---

## é…ç½®
é…ç½®æ–‡ä»¶è·¯å¾„ï¼š`configs/vllm.yaml`  

ä¸‹è½½æ¨¡å‹ï¼š
```bash
huggingface-cli login
python download_model.py
```

ç¤ºä¾‹ï¼š
```yaml
model_name: ./model/LLM-Research/Meta-Llama-3-8B-Instruct
tensor_parallel_size: 1
gpu_memory_utilization: 0.9
max_model_len: 8192
enable_lora: true
max_lora_rank: 64
trust_remote_code: true
```

### é…ç½®è·¯å¾„æŒ‡å®š
ç¨‹åºä¼šä¼˜å…ˆè¯»å–ç¯å¢ƒå˜é‡ï¼š
```bash
export VLLM_CONFIG_PATH= ../GPT/configs/vllm.yaml
```
è‹¥æœªè®¾ç½®ï¼Œåˆ™é»˜è®¤ä½¿ç”¨ `configs/vllm.yaml`ã€‚

---

## å¯åŠ¨æœåŠ¡
åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼š
```bash
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
```

è®¿é—®ï¼š
- å¥åº·æ£€æŸ¥: [http://localhost:8000/healthz](http://localhost:8000/healthz)  
- API æ–‡æ¡£: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## API è°ƒç”¨ç¤ºä¾‹

### é€šç”¨ç”Ÿæˆ
```bash
curl -X POST http://localhost:8000/v1/generate   -H "Content-Type: application/json"   -d '{
    "prompt": "ä»‹ç»ä¸€ä¸‹å‡¤æ¢¨é…¥ç¤¼ç›’ã€‚",
    "language": "zh",
    "style": "persuasive",
    "max_tokens": 200,
    "temperature": 0.7,
    "top_p": 0.9,
    "stop_sequences": []
  }'
```

### å•†å“æ¨å¹¿æ–‡æ¡ˆ
```bash
curl -X POST http://localhost:8000/v1/generate/product   -H "Content-Type: application/json"   -d '{"prompt":"æ–°å“å¥¶èŒ¶è”åç¤¼ç›’","language":"zh","style":"casual","max_tokens":150,"temperature":0.7,"top_p":0.9,"stop_sequences":[]}'
```

---

## ğŸ’» å®¢æˆ·ç«¯è„šæœ¬

### 1. äº¤äº’å¼å¯¹è¯
```bash
python clients/python/chatagent.py --lang zh --style persuasive --type chat
```
è¾“å…¥ `/exit` å¯é€€å‡ºã€‚

### 2. ä¸€æ¬¡æ€§ç”Ÿæˆ
ç›´æ¥è¾“å…¥æ–‡æœ¬ï¼š
```bash
python clients/python/gen_once.py --type product --lang zh --style authoritative   --text "è¿™æ˜¯ä¸€å®¶ä¸»è¥å°æ¹¾å‡¤æ¢¨é…¥çš„åº—é“ºï¼Œæ¨å‡ºäº†è”åå¥¶èŒ¶ç¤¼ç›’ã€‚"
```
æˆ–

```bash
python clients/python/gen_once.py --type product --lang en --style authoritative --text "This is a Taiwanese pastry shop specializing in pineapple cakes, now launching a co-branded bubble tea gift box."
```
æˆ–

```bash
python clients/python/gen_once.py --type product --lang es --style authoritative --text "Esta es una pastelerÃ­a taiwanesa especializada en pasteles de piÃ±a, que ahora lanza una caja de regalo en colaboraciÃ³n con tÃ© de burbujas."
```


ä»æ–‡ä»¶è¯»å–ï¼š
```bash
python clients/python/gen_once.py --type video --lang zh --style casual   --infile ./samples/topic.txt   --outfile ./out/video.txt
```

## ğŸ“œ License
MIT License
